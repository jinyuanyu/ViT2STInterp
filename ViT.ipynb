{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04fe905-d67e-4057-95f7-df2c0e391dd1",
   "metadata": {},
   "source": [
    "# 从Hugging Face上拉取ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd7585-b34b-4bb1-915e-91d16073ee02",
   "metadata": {},
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75402513-6477-47b5-8496-3b43750384cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1666595566.845855\n",
      "Epoch [2/10], Loss: 1666386644.4509685\n",
      "Epoch [3/10], Loss: 1666340013.930888\n",
      "Epoch [4/10], Loss: 1666314923.534682\n",
      "Epoch [5/10], Loss: 1666293931.3936207\n",
      "Epoch [6/10], Loss: 1666273793.1288376\n",
      "Epoch [7/10], Loss: 1666252629.3849704\n",
      "Epoch [8/10], Loss: 1666230784.4244547\n",
      "Epoch [9/10], Loss: 1666209109.7028522\n",
      "Epoch [10/10], Loss: 1666187264.015358\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "class ViTForInterpolation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTForInterpolation, self).__init__()\n",
    "        config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        config.num_channels = 1  # 修改通道数为1\n",
    "        self.vit = ViTModel(config)\n",
    "        \n",
    "        # 根据输入图像的大小定义卷积层\n",
    "        self.conv = nn.Conv2d(config.hidden_size, 1, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(pixel_values=x).last_hidden_state\n",
    "        batch_size, num_patches, hidden_size = outputs.shape\n",
    "        \n",
    "        # 去掉分类 token\n",
    "        num_patches = num_patches - 1\n",
    "        outputs = outputs[:, 1:, :]  # [batch_size, num_patches, hidden_size]\n",
    "        \n",
    "        # 计算patch数量\n",
    "        patch_size = 16  # 假设patch大小是16x16\n",
    "        num_patches_per_dim = int((num_patches ** 0.5))\n",
    "        \n",
    "        # 调整输出维度\n",
    "        outputs = outputs.view(batch_size, num_patches_per_dim, num_patches_per_dim, hidden_size)\n",
    "        outputs = outputs.permute(0, 3, 1, 2)  # [batch_size, hidden_size, num_patches_per_dim, num_patches_per_dim]\n",
    "        \n",
    "        # 使用卷积层将输出映射到目标图像尺寸\n",
    "        outputs = self.conv(outputs)  # [batch_size, 1, num_patches_per_dim, num_patches_per_dim]\n",
    "        \n",
    "        # 上采样到原始图像尺寸\n",
    "        outputs = self.upsample(outputs)  # [batch_size, 1, 224, 224]\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTForInterpolation().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "def masked_mse_loss(output, target, mask):\n",
    "    loss = (output - target) ** 2\n",
    "    loss = loss * mask  # 应用掩码\n",
    "    return torch.sum(loss) / torch.sum(mask)  # 只对非掩码区域求平均\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for data, mask in dataloader:\n",
    "        if torch.isnan(data).any() or torch.isinf(data).any():\n",
    "            print(\"Input data contains NaN or inf values\")\n",
    "        if torch.isnan(mask).any() or torch.isinf(mask).any():\n",
    "            print(\"Mask contains NaN or inf values\")\n",
    "        data, mask = data.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # 只对掩码为1的区域计算损失\n",
    "        loss = masked_mse_loss(outputs, data, mask)\n",
    "                \n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea75fb1f-42b3-4032-bb08-5c319dcf60ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([8, 1, 224, 224])\n",
      "data shape: torch.Size([8, 1, 224, 224])\n",
      "mask shape: torch.Size([8, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(\"outputs shape:\", outputs.shape)\n",
    "print(\"data shape:\", data.shape)\n",
    "print(\"mask shape:\", mask.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
